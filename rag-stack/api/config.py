"""
config.py
=========

RAG-Stack API konfig√ºrasyon mod√ºl√º.

T√ºm environment deƒüi≈ükenleri ve sabit ayarlar burada merkezi olarak y√∂netilir.

üÜï v0.5.0: √áoklu LLM Provider desteƒüi
    - Local (Ollama)
    - Groq Cloud
    - OpenRouter
    - Google AI Studio (Gemini)
    - Cerebras
"""

import os
from dotenv import load_dotenv
from pymongo import MongoClient
from qdrant_client import QdrantClient
from sentence_transformers import SentenceTransformer

# ============================================================================
# ENV LOAD
# ============================================================================

load_dotenv()

# ============================================================================
# BASIC SETTINGS
# ============================================================================

ENV = os.getenv("ENV", "development").lower()
DEBUG = ENV in ("dev", "development")

# ============================================================================
# LRS (MONGO) CONFIG
# ============================================================================

LRS_MONGO_HOST = os.getenv("LRS_MONGO_HOST", "lrs-app")
LRS_MONGO_PORT = int(os.getenv("LRS_MONGO_PORT", 27017))
LRS_MONGO_DB = os.getenv("LRS_MONGO_DB") or os.getenv("LRS_MONGO_DB_NAME", "learninglocker")
LRS_MONGO_COLLECTION = os.getenv("LRS_MONGO_COLLECTION", "statements")

mongo_client = MongoClient(f"mongodb://{LRS_MONGO_HOST}:{LRS_MONGO_PORT}")
lrs_db = mongo_client[LRS_MONGO_DB]
lrs_statements = lrs_db[LRS_MONGO_COLLECTION]

# ============================================================================
# QDRANT CONFIG
# ============================================================================

QDRANT_HOST = os.getenv("QDRANT_HOST", "rag-qdrant")
QDRANT_PORT = int(os.getenv("QDRANT_PORT", 6333))

qdrant_client = QdrantClient(
    host=QDRANT_HOST,
    port=QDRANT_PORT,
)

# ============================================================================
# EMBEDDING MODEL
# ============================================================================

EMBEDDING_MODEL_NAME = os.getenv(
    "EMBEDDING_MODEL",
    "sentence-transformers/all-MiniLM-L6-v2",
)

embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)

# ============================================================================
# OLLAMA (LOCAL LLM) CONFIG
# ============================================================================

RAW_OLLAMA_HOST = os.getenv("OLLAMA_HOST", "llm-ollama")
OLLAMA_PORT = os.getenv("OLLAMA_PORT", "11434")

if RAW_OLLAMA_HOST.startswith("http://") or RAW_OLLAMA_HOST.startswith("https://"):
    OLLAMA_HOST = RAW_OLLAMA_HOST.rstrip("/")
else:
    OLLAMA_HOST = f"http://{RAW_OLLAMA_HOST}:{OLLAMA_PORT}"

LLM_MODEL_NAME = os.getenv("LLM_MODEL") or os.getenv("LLM_MODEL_NAME", "gemma2:2b")

# ============================================================================
# üÜï LLM PROVIDER API KEYS
# ============================================================================

GROQ_API_KEY = os.getenv("GROQ_API_KEY", "")
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY", "")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY", "")
CEREBRAS_API_KEY = os.getenv("CEREBRAS_API_KEY", "")
MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY", "")

# ============================================================================
# üÜï LLM PROVIDER ENDPOINTS
# ============================================================================

GROQ_API_BASE = "https://api.groq.com/openai/v1"
OPENROUTER_API_BASE = "https://openrouter.ai/api/v1"
GOOGLE_API_BASE = "https://generativelanguage.googleapis.com/v1beta"
CEREBRAS_API_BASE = "https://api.cerebras.ai/v1"
MISTRAL_API_BASE = "https://api.mistral.ai/v1"

# ============================================================================
# DEFAULT LLM SETTINGS
# ============================================================================

DEFAULT_LLM_PROVIDER = os.getenv("DEFAULT_LLM_PROVIDER", "local")
DEFAULT_LLM_MODEL = os.getenv("DEFAULT_LLM_MODEL", "gemma2:2b")
DEFAULT_LLM_ROLE = os.getenv("DEFAULT_LLM_ROLE", "servis_analisti")
DEFAULT_LLM_BEHAVIOR = os.getenv("DEFAULT_LLM_BEHAVIOR", "balanced")

# ============================================================================
# üÜï PROVIDER MODEL CATALOGS
# ============================================================================

PROVIDER_MODELS = {
    "groq": [
        {"value": "llama-3.3-70b-versatile", "label": "Llama 3.3 (70B) ‚Ä¢ G√º√ßl√º", "description": "En pop√ºler"},
        {"value": "llama-3.1-8b-instant", "label": "Llama 3.1 (8B) ‚Ä¢ Ultra Hƒ±zlƒ±", "description": "Anlƒ±k yanƒ±t"},
        {"value": "qwen/qwen3-32b", "label": "Qwen 3 (32B) ‚Ä¢ √áok Dilli", "description": "T√ºrk√ße iyi"},
        {"value": "moonshotai/kimi-k2-instruct", "label": "Kimi K2 ‚Ä¢ Yeni", "description": "Moonshot AI"},
        # {"value": "openai/gpt-oss-120b", "label": "GPT-OSS (120B) ‚Ä¢ Dev", "description": "OpenAI a√ßƒ±k"},
        {"value": "openai/gpt-oss-20b", "label": "GPT-OSS (20B) ‚Ä¢ Orta", "description": "Dengeli"},
        {"value": "groq/compound", "label": "Compound ‚Ä¢ Groq Native", "description": "Groq'un modeli"},
        # {"value": "allam-2-7b", "label": "ALLaM 2 (7B) ‚Ä¢ Arap√ßa", "description": "Arap dili uzmanƒ±"},
    ],
    "openrouter": [
        # Anthropic
        # {"value": "anthropic/claude-sonnet-4", "label": "Claude Sonnet 4 ‚Ä¢ G√ºncel", "description": "Dengeli, hƒ±zlƒ±"},
        # {"value": "anthropic/claude-sonnet-4.5", "label": "Claude Sonnet 4.5 ‚Ä¢ En Yeni", "description": "En g√ºncel"},
        # {"value": "anthropic/claude-3.5-sonnet", "label": "Claude 3.5 Sonnet ‚Ä¢ Pop√ºler", "description": "Stabil"},
        {"value": "anthropic/claude-3.5-haiku", "label": "Claude 3.5 Haiku ‚Ä¢ Hƒ±zlƒ±", "description": "Ekonomik"},
        # OpenAI
        # {"value": "openai/gpt-4o", "label": "GPT-4o ‚Ä¢ Multimodal", "description": "OpenAI flagship"},
        {"value": "openai/gpt-4o-mini", "label": "GPT-4o Mini ‚Ä¢ Ekonomik", "description": "Hƒ±zlƒ±, ucuz"},
        {"value": "openai/o3-mini", "label": "O3 Mini ‚Ä¢ Reasoning", "description": "Muhakeme"},
        # Google
        {"value": "google/gemini-2.5-flash", "label": "Gemini 2.5 Flash", "description": "Google via OR"},
        # {"value": "google/gemini-2.5-pro", "label": "Gemini 2.5 Pro", "description": "Google g√º√ßl√º"},
        # Meta
        {"value": "meta-llama/llama-3.3-70b-instruct", "label": "Llama 3.3 (70B)", "description": "A√ßƒ±k kaynak"},
        {"value": "meta-llama/llama-4-maverick", "label": "Llama 4 Maverick ‚Ä¢ Yeni", "description": "En g√ºncel"},
        # DeepSeek
        {"value": "deepseek/deepseek-chat", "label": "DeepSeek Chat ‚Ä¢ Ucuz", "description": "√áin, ekonomik"},
        {"value": "deepseek/deepseek-r1", "label": "DeepSeek R1 ‚Ä¢ Reasoning", "description": "Muhakeme"},
        # Qwen
        {"value": "qwen/qwq-32b", "label": "QwQ (32B) ‚Ä¢ Reasoning", "description": "Qwen muhakeme"},
        # {"value": "qwen/qwen-max", "label": "Qwen Max ‚Ä¢ En G√º√ßl√º", "description": "Alibaba flagship"},
        # # Mistral
        # {"value": "mistralai/mistral-large-2411", "label": "Mistral Large", "description": "Avrupa lideri"},
    ],
    "google": [
        {"value": "gemini-2.5-flash", "label": "Gemini 2.5 Flash ‚Ä¢ En Yeni", "description": "Hƒ±zlƒ±, g√ºncel"},
        # {"value": "gemini-2.5-pro", "label": "Gemini 2.5 Pro ‚Ä¢ En G√º√ßl√º", "description": "En akƒ±llƒ±"},
        # {"value": "gemini-2.0-flash", "label": "Gemini 2.0 Flash ‚Ä¢ Stabil", "description": "Dengeli"},
        # {"value": "gemini-2.0-flash-lite", "label": "Gemini 2.0 Flash Lite ‚Ä¢ Hafif", "description": "Ultra hƒ±zlƒ±"},
        # {"value": "gemma-3-27b-it", "label": "Gemma 3 (27B) ‚Ä¢ A√ßƒ±k", "description": "G√º√ßl√º, a√ßƒ±k kaynak"},
        # {"value": "gemma-3-12b-it", "label": "Gemma 3 (12B) ‚Ä¢ Orta", "description": "Dengeli"},
    ],
    "cerebras": [
        {"value": "llama-3.3-70b", "label": "Llama 3.3 (70B) ‚Ä¢ G√º√ßl√º", "description": "450 token/sn"},
        {"value": "llama3.1-8b", "label": "Llama 3.1 (8B) ‚Ä¢ Ultra Hƒ±zlƒ±", "description": "2100 token/sn"},
        {"value": "qwen-3-235b-a22b-instruct-2507", "label": "Qwen 3 (235B) ‚Ä¢ Dev", "description": "MoE, √ßok g√º√ßl√º"},
        {"value": "qwen-3-32b", "label": "Qwen 3 (32B) ‚Ä¢ Dengeli", "description": "√áok dilli"},
        {"value": "gpt-oss-120b", "label": "GPT-OSS (120B) ‚Ä¢ A√ßƒ±k", "description": "OpenAI a√ßƒ±k kaynak"},
        # {"value": "zai-glm-4.6", "label": "GLM 4.6 ‚Ä¢ √áin", "description": "Zhipu AI"},
    ],
    "mistral": [
        {"value": "mistral-large-latest", "label": "Mistral Large ‚Ä¢ Flagship", "description": "En g√º√ßl√º"},
        {"value": "mistral-medium-latest", "label": "Mistral Medium ‚Ä¢ Dengeli", "description": "Performans/maliyet"},
        {"value": "mistral-small-latest", "label": "Mistral Small ‚Ä¢ Hƒ±zlƒ±", "description": "Ekonomik"},
        {"value": "codestral-latest", "label": "Codestral ‚Ä¢ Kod Uzmanƒ±", "description": "Kod √ºretimi"},
        {"value": "open-mistral-nemo", "label": "Mistral Nemo ‚Ä¢ A√ßƒ±k", "description": "12B, a√ßƒ±k kaynak"},
        {"value": "ministral-8b-latest", "label": "Ministral (8B) ‚Ä¢ Kompakt", "description": "Edge i√ßin"},
        {"value": "pixtral-large-latest", "label": "Pixtral Large ‚Ä¢ G√∂rsel", "description": "Multimodal"},
        {"value": "devstral-latest", "label": "Devstral ‚Ä¢ Geli≈ütirici", "description": "Kod + reasoning"},
    ],
    "local": [
        {"value": "gemma2:2b", "label": "Gemma 2 (2B) ‚Ä¢ Ultra Hafif", "description": "En hƒ±zlƒ± yanƒ±t"},
        {"value": "qwen2.5:0.5b", "label": "Qwen 2.5 (0.5B) ‚Ä¢ Minimal", "description": "√áok hafif"},
        {"value": "llama3.2:3b", "label": "Llama 3.2 (3B) ‚Ä¢ Hƒ±zlƒ± Yanƒ±t", "description": "Dengeli hƒ±z"},
        {"value": "llama3.1:8b", "label": "Llama 3.1 (8B) ‚Ä¢ Genel Ama√ßlƒ±", "description": "√ñnerilen"},
        {"value": "RefinedNeuro/Turkcell-LLM-7b-v1:latest", "label": "Turkcell (7B) ‚Ä¢ T√ºrk√ße Uzman", "description": "T√ºrk√ße optimize"},
        {"value": "RefinedNeuro/RN_TR_R2:latest", "label": "TR-R2 (8B) ‚Ä¢ T√ºrk√ße Muhakeme", "description": "Geli≈ümi≈ü T√ºrk√ße"},
        {"value": "aya-expanse:8b", "label": "Aya (8B) ‚Ä¢ √áok Dilli", "description": "√áok dil desteƒüi"},
    ],
}

# ============================================================================
# PROVIDER DEFAULT MODELS
# ============================================================================

PROVIDER_DEFAULTS = {
    "local": "gemma2:2b",
    "groq": "llama-3.3-70b-versatile",
    "openrouter": "anthropic/claude-3.5-haiku",
    "google": "gemini-2.5-flash",
    "cerebras": "llama-3.3-70b",
    "mistral": "mistral-large-latest",
}

# ============================================================================
# PROVIDER METADATA
# ============================================================================

PROVIDERS_CONFIG = {
    "local": {
        "id": "local",
        "name": "Local (Ollama)",
        "icon": "üè†",
        "description": "Yerel sunucuda √ßalƒ±≈üan Ollama modelleri",
        "pricing": "√úcretsiz (kendi donanƒ±mƒ±nƒ±z)",
        "latency": "Donanƒ±ma baƒülƒ±",
    },
    "groq": {
        "id": "groq",
        "name": "Groq Cloud",
        "icon": "‚ö°",
        "description": "Groq LPU ile ultra hƒ±zlƒ± inference",
        "pricing": "√áok d√º≈ü√ºk maliyet",
        "latency": "~100ms",
    },
    "openrouter": {
        "id": "openrouter",
        "name": "OpenRouter",
        "icon": "üåê",
        "description": "Claude, GPT-4, Gemini ve 200+ model tek API'de",
        "pricing": "Model bazlƒ± (kullandƒ±k√ßa √∂de)",
        "latency": "Model bazlƒ±",
    },
    "google": {
        "id": "google",
        "name": "Google AI Studio",
        "icon": "üî∑",
        "description": "Google Gemini modelleri",
        "pricing": "√úcretsiz tier + kullandƒ±k√ßa √∂de",
        "latency": "~200ms",
    },
    "cerebras": {
        "id": "cerebras",
        "name": "Cerebras",
        "icon": "üß†",
        "description": "D√ºnyanƒ±n en hƒ±zlƒ± AI inference (2100 token/sn)",
        "pricing": "D√º≈ü√ºk maliyet",
        "latency": "~50ms",
    },
    "mistral": {
        "id": "mistral",
        "name": "Mistral AI",
        "icon": "üåÄ",
        "description": "Avrupa'nƒ±n lider AI ≈üirketi, g√º√ßl√º a√ßƒ±k modeller",
        "pricing": "Rekabet√ßi fiyatlandƒ±rma",
        "latency": "~150ms",
    },
}

# ============================================================================
# LLM ROLES
# ============================================================================

LLM_ROLES = [
    {"value": "servis_analisti", "label": "Servis Analisti", "description": "Operasyonel analiz"},
    {"value": "filo_yoneticisi", "label": "Filo Y√∂neticisi", "description": "Filo y√∂netimi"},
    {"value": "teknik_uzman", "label": "Teknik Uzman", "description": "Teknik detay"},
    {"value": "musteri_temsilcisi", "label": "M√º≈üteri Temsilcisi", "description": "M√º≈üteri odaklƒ±"},
    {"value": "egitmen", "label": "Eƒüitmen", "description": "Eƒüitim ama√ßlƒ±"},
    {"value": "tedarik_zinciri_uzmani", "label": "Tedarik Zinciri Uzmanƒ±", "description": "Lojistik odaklƒ±"},
    {"value": "cto", "label": "CTO", "description": "Stratejik bakƒ±≈ü"},
]

# ============================================================================
# LLM BEHAVIORS
# ============================================================================

LLM_BEHAVIORS = [
    {"value": "balanced", "label": "Analitik Yakla≈üƒ±m", "description": "√ñnerilen"},
    {"value": "commentary", "label": "Yorumlayƒ±cƒ±", "description": "A√ßƒ±klayƒ±cƒ±"},
    {"value": "predictive", "label": "Hipotez √úreten", "description": "Senaryo tabanlƒ±"},
    {"value": "report", "label": "Rapor Olu≈üturan", "description": "Yapƒ±landƒ±rƒ±lmƒ±≈ü"},
]

# ============================================================================
# API / GENERAL SETTINGS
# ============================================================================

MAX_EXAMPLE_STATEMENTS = int(os.getenv("MAX_EXAMPLE_STATEMENTS", 5))
DEFAULT_TIMEZONE = "Europe/Istanbul"

# ============================================================================
# LRS / LLM LIMIT SETTINGS
# ============================================================================

STATS_TABLE_LIMIT = int(os.getenv("STATS_TABLE_LIMIT", 200))
DOMAIN_STATS_LIMIT = int(os.getenv("DOMAIN_STATS_LIMIT", 200))
LLM_CONTEXT_MAX_ROWS = int(os.getenv("LLM_CONTEXT_MAX_ROWS", 20))

# ============================================================================
# EXPORT
# ============================================================================

__all__ = [
    # Basic
    "ENV",
    "DEBUG",
    # MongoDB
    "lrs_statements",
    "lrs_db",
    "mongo_client",
    # Qdrant
    "qdrant_client",
    # Embedding
    "embedding_model",
    "EMBEDDING_MODEL_NAME",
    # Ollama
    "OLLAMA_HOST",
    "LLM_MODEL_NAME",
    # Limits
    "MAX_EXAMPLE_STATEMENTS",
    "DEFAULT_TIMEZONE",
    "STATS_TABLE_LIMIT",
    "DOMAIN_STATS_LIMIT",
    "LLM_CONTEXT_MAX_ROWS",
    # üÜï LLM Provider API Keys
    "GROQ_API_KEY",
    "OPENROUTER_API_KEY",
    "GOOGLE_API_KEY",
    "CEREBRAS_API_KEY",
    "MISTRAL_API_KEY",
    # üÜï LLM Provider Endpoints
    "GROQ_API_BASE",
    "OPENROUTER_API_BASE",
    "GOOGLE_API_BASE",
    "CEREBRAS_API_BASE",
    "MISTRAL_API_BASE",
    # üÜï LLM Provider Config
    "DEFAULT_LLM_PROVIDER",
    "DEFAULT_LLM_MODEL",
    "DEFAULT_LLM_ROLE",
    "DEFAULT_LLM_BEHAVIOR",
    "PROVIDER_MODELS",
    "PROVIDER_DEFAULTS",
    "PROVIDERS_CONFIG",
    "LLM_ROLES",
    "LLM_BEHAVIORS",
]
