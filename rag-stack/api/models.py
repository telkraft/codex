"""
models.py
=========

Merkezi model tanÄ±mlarÄ±.

- DÄ±ÅŸ API istek/cevap modelleri (Pydantic BaseModel)
- LRS sorgu planÄ± ve domain senaryolarÄ± (dataclass / yardÄ±mcÄ± modeller)
- ðŸ†• LLM Provider modelleri (5 provider desteÄŸi)

NOT: Canonical Question modelleri (QuestionType, OutputShape, CanonicalQuestion)
     artÄ±k canonical_questions.py dosyasÄ±nda tanÄ±mlÄ±dÄ±r.
     
     2-KatmanlÄ± Mimari:
       - KATMAN 1 (Intent): QuestionType - Sorunun konusu (NE?)
       - KATMAN 2 (Shape): OutputShape - Verinin sunumu (NASIL?)
"""

from __future__ import annotations

from dataclasses import dataclass, field
from typing import Any, Dict, List, Literal, Optional
from datetime import datetime
from enum import Enum

from pydantic import BaseModel


# ============================================================================
# ðŸ†• LLM Provider Modelleri
# ============================================================================


class LLMProviderType(str, Enum):
    """
    Desteklenen LLM saÄŸlayÄ±cÄ± tipleri.
    
    ðŸ†• v0.5.0: 6 provider desteÄŸi
    """
    LOCAL = "local"           # Ollama (yerel)
    GROQ = "groq"             # Groq Cloud (LPU)
    OPENROUTER = "openrouter" # OpenRouter (multi-model gateway)
    GOOGLE = "google"         # Google AI Studio (Gemini)
    CEREBRAS = "cerebras"     # Cerebras (ultra-fast inference)
    MISTRAL = "mistral"       # Mistral AI (Avrupa'nÄ±n lideri)


class ProviderModelInfo(BaseModel):
    """Tek bir model hakkÄ±nda bilgi."""
    value: str           # Model ID (API'ye gÃ¶nderilecek)
    label: str           # UI'da gÃ¶sterilecek isim
    description: str     # KÄ±sa aÃ§Ä±klama


class ProviderInfo(BaseModel):
    """Bir LLM saÄŸlayÄ±cÄ± hakkÄ±nda tam bilgi."""
    id: str                              # Provider ID (local, groq, openrouter, google, cerebras)
    name: str                            # GÃ¶rÃ¼nen isim
    icon: str                            # Emoji/ikon
    description: Optional[str] = None    # AÃ§Ä±klama
    models: List[ProviderModelInfo]      # KullanÄ±labilir modeller
    default_model: str                   # VarsayÄ±lan model
    pricing: Optional[str] = None        # FiyatlandÄ±rma bilgisi
    latency: Optional[str] = None        # Tipik gecikme sÃ¼resi


class RoleInfo(BaseModel):
    """LLM rol bilgisi."""
    value: str           # Rol ID
    label: str           # GÃ¶rÃ¼nen isim
    description: str     # AÃ§Ä±klama


class BehaviorInfo(BaseModel):
    """LLM davranÄ±ÅŸ bilgisi."""
    value: str           # DavranÄ±ÅŸ ID
    label: str           # GÃ¶rÃ¼nen isim
    description: str     # AÃ§Ä±klama


class LLMDefaults(BaseModel):
    """VarsayÄ±lan LLM ayarlarÄ±."""
    provider: str
    model: str
    role: str
    behavior: str


class LLMConfigResponse(BaseModel):
    """
    /llm/config endpoint'inden dÃ¶nen tam konfigÃ¼rasyon.
    
    Frontend bu endpoint'i Ã§aÄŸÄ±rarak tÃ¼m LLM ayarlarÄ±nÄ± dinamik olarak alÄ±r.
    """
    providers: List[ProviderInfo]
    roles: List[RoleInfo]
    behaviors: List[BehaviorInfo]
    defaults: LLMDefaults


# ============================================================================
# DÄ±ÅŸ API Modelleri (FastAPI endpoint'leri iÃ§in)
# ============================================================================


class ChatRequest(BaseModel):
    """
    /chat endpoint'ine gelen istek modeli.

    Streamlit tarafÄ±ndaki payload ile bire bir uyumlu olacak ÅŸekilde:
      {
        "query": "...",
        "collection": "man_local_service_maintenance",
        "use_llm": true,
        "limit": 100,
        "provider": "groq",        # ðŸ†• 5 provider destekleniyor
        "model": "llama-3.3-70b-versatile",
        "role": "service_analyst",
        "behavior": "balanced"
      }
    """

    query: str
    collection: Optional[str] = None

    # LLM kullanÄ±lsÄ±n mÄ±?
    use_llm: bool = True

    # LRS / RAG baÄŸlam limiti
    limit: Optional[int] = 100

    # ðŸ†• LLM provider (local, groq, openrouter, google, cerebras)
    provider: Optional[str] = None

    # LLM modeli
    model: Optional[str] = None

    # Sistem rolÃ¼ / persona
    role: Optional[str] = None

    # DavranÄ±ÅŸ modu
    behavior: Optional[str] = "balanced"

    # Soru dili
    language: Optional[str] = "tr"

    # Debug modu
    debug: bool = False


class StatsTable(BaseModel):
    """
    UI'de gÃ¶sterilecek ve LLM'e baÄŸlam olarak gÃ¶nderilecek tablo yapÄ±sÄ±.
    """

    title: str
    description: Optional[str] = None

    columns: List[str]
    rows: List[Dict[str, Any]]

    meta: Optional[Dict[str, Any]] = None


class ExampleStatement(BaseModel):
    """
    Ã–rnek xAPI statement'larÄ± iÃ§in sadeleÅŸtirilmiÅŸ model.
    """

    statement_id: Optional[str] = None
    raw: Optional[Dict[str, Any]] = None

    vehicle_id: Optional[str] = None
    vehicle_model: Optional[str] = None
    vehicle_type: Optional[str] = None

    service_location: Optional[str] = None
    customer_id: Optional[str] = None

    operation_date: Optional[str] = None

    verb_type: Optional[str] = None

    material_name: Optional[str] = None
    material_code: Optional[str] = None
    material_family: Optional[str] = None

    fault_code: Optional[str] = None

    odometer_km: Optional[float] = None
    cost: Optional[float] = None
    discount: Optional[float] = None

    text: str


class LLMAnalysis(BaseModel):
    """
    LLM'in nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± ve ne Ã¼rettiÄŸini anlatan model.
    """

    # ðŸ†• Hangi provider kullanÄ±ldÄ±?
    provider: Optional[str] = None

    # Hangi model kullanÄ±ldÄ±?
    model: Optional[str] = None

    # KullanÄ±cÄ±ya gÃ¶sterilecek ana cevap
    answer: Optional[str] = None

    # Zamanlama bilgileri (sn cinsinden)
    latency_sec: Optional[float] = None

    # Token istatistikleri
    prompt_tokens: Optional[int] = None
    completion_tokens: Optional[int] = None
    total_tokens: Optional[int] = None

    # ðŸ†• Provider spesifik bilgiler
    provider_info: Optional[Dict[str, Any]] = None

    # Reasoning / zincir aÃ§Ä±klamasÄ±
    reasoning: Optional[str] = None


class ChatResponse(BaseModel):
    """
    /chat endpoint'inin standart cevap modeli.
    """

    intent: str
    scenario: Optional[str] = None
    summary: Optional[str] = None

    data: Optional[Dict[str, Any]] = None

    tables: Optional[List[StatsTable]] = None
    examples: Optional[List[ExampleStatement]] = None
    llm: Optional[LLMAnalysis] = None


class SearchRequest(BaseModel):
    """
    /search endpoint'i iÃ§in istek modeli.
    """

    query: str
    collection: str
    limit: int = 10


class XAPIIngestRequest(BaseModel):
    """
    /xapi/ingest endpoint'i iÃ§in istek modeli.
    """

    lrs_endpoint: str
    username: Optional[str] = None
    password: Optional[str] = None
    collection: str
    limit: Optional[int] = 100
    max_pages: Optional[int] = 10
    page_delay_ms: Optional[int] = 0


class DocumentUploadResponse(BaseModel):
    """
    DokÃ¼man yÃ¼kleme cevap ÅŸemasÄ±.
    """

    filename: str
    chunks: int
    collection: str
    status: str


# ============================================================================
# LRS Sorgu PlanÄ± ve Zaman Modeli
# ============================================================================

@dataclass
class TimeRange:
    """
    LRS tarafÄ±nda tarih aralÄ±ÄŸÄ± filtresi iÃ§in model.
    """

    field: str = "operationDate"

    # Eski string tabanlÄ± alanlar
    start: Optional[str] = None
    end: Optional[str] = None

    # Yeni datetime tabanlÄ± alanlar
    start_date: Optional[datetime] = None
    end_date: Optional[datetime] = None


@dataclass
class QueryPlan:
    """
    LRS'e karÅŸÄ± Ã§alÄ±ÅŸacak schema-aware istatistiksel sorgu planÄ±.
    """

    mode: Literal["statistical", "semantic", "hybrid"] = "statistical"

    group_by: List[str] = field(default_factory=list)
    filters: Dict[str, Any] = field(default_factory=dict)
    metrics: List[str] = field(default_factory=list)

    time_range: Optional[TimeRange] = None

    sort_by: Optional[str] = None
    limit: Optional[int] = None


# ============================================================================
# Top Entities & Gelecek DÃ¶nem ÅžemasÄ±
# ============================================================================


@dataclass
class FuturePeriodSpec:
    """
    Basit Ã¶ngÃ¶rÃ¼ iÃ§in zaman dilimi tanÄ±mÄ±.
    """

    kind: Literal["month", "season", "year", "last_n_months", "last_n_years"]

    year: Optional[int] = None
    month: Optional[int] = None
    season: Optional[str] = None

    value: Optional[int] = None
    anchor_year: Optional[int] = None
    anchor_month: Optional[int] = None


@dataclass
class TopEntitiesQuestion:
    """
    Eski "en Ã§ok gelen ..." sorgularÄ± iÃ§in soru modeli.
    """

    entity_type: str

    question_type: Literal["current_top", "future_top"] = "current_top"

    limit: int = 5

    service_filter: Optional[str] = None
    period: Optional[Dict[str, Any]] = None

    material_filter: Optional[str] = None
    model_filter: Optional[str] = None
    vehicle_filter: Optional[str] = None

    future_period: Optional[FuturePeriodSpec] = None


@dataclass
class PeriodSpec:
    """
    Ä°nsan-dili dÃ¶nem tanÄ±mÄ±.
    """

    kind: Literal["year", "season", "range", "relative", "month"]

    year: Optional[int] = None
    season: Optional[str] = None

    month: Optional[int] = None

    start_date: Optional[str] = None
    end_date: Optional[str] = None

    unit: Optional[Literal["year", "month"]] = None
    value: Optional[int] = None


# ============================================================================
# __all__
# ============================================================================

__all__ = [
    # ðŸ†• LLM Provider Modelleri
    "LLMProviderType",
    "ProviderModelInfo",
    "ProviderInfo",
    "RoleInfo",
    "BehaviorInfo",
    "LLMDefaults",
    "LLMConfigResponse",
    
    # API Modelleri
    "ChatRequest",
    "ChatResponse",
    "StatsTable",
    "ExampleStatement",
    "LLMAnalysis",
    "SearchRequest",
    "XAPIIngestRequest",
    "DocumentUploadResponse",
    
    # LRS Modelleri
    "TimeRange",
    "QueryPlan",
    
    # Domain/Pattern Modelleri
    "FuturePeriodSpec",
    "TopEntitiesQuestion",
    "PeriodSpec",
]
